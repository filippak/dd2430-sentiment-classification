{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9a160dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "# !pip install transformers==4.3.2\n",
    "import torch\n",
    "import io\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import numpy as np\n",
    "import time\n",
    "import math\n",
    "import datetime\n",
    "import torch.nn as nn\n",
    "from typing import Union\n",
    "from transformers import *\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "#!pip install torch==1.7.1+cu101 torchvision==0.8.2+cu101 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "#!pip install sentencepiece\n",
    "\n",
    "##Set random values\n",
    "seed_val = 42\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "if torch.cuda.is_available():\n",
    "  torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "#client = bigquery.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f9fdd1c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have  6794  unlabeled comments\n",
      "You're using:  959  labeled comments.\n",
      "Negative: 74% (710)\n",
      "Positive: 25% (249)\n"
     ]
    }
   ],
   "source": [
    "# Load the filtered unlabeled comments and all the labeled comments.\n",
    "fb_comments_unlabeled_df = pd.read_pickle(\"./unlabeled_filtered_comments.pkl\")\n",
    "fb_comments_labeled_df = pd.read_pickle(\"./labeled_comments.pkl\")\n",
    "\n",
    "print(\"You have \", len(fb_comments_unlabeled_df), \" unlabeled comments\")\n",
    "print(\"You're using: \", len(fb_comments_labeled_df), \" labeled comments.\")\n",
    "n_neg, n_pos = fb_comments_labeled_df[\"sentiment_label\"].value_counts()[0], fb_comments_labeled_df[\"sentiment_label\"].value_counts()[1]\n",
    "print(\"Negative: %d%% (%d)\" %(n_neg*100/len(fb_comments_labeled_df), n_neg))\n",
    "print(\"Positive: %d%% (%d)\" %(n_pos*100/len(fb_comments_labeled_df), n_pos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f28faa65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(959, 5)\n"
     ]
    }
   ],
   "source": [
    "# Select a percentage (of the unlabeled comments) for the labeled data. At this moment, we have 6794 comments in total.\n",
    "             \n",
    "def create_test_set(labeled_comments: pd.core.frame.DataFrame, test_size: Union[int, float]) -> tuple:\n",
    "        print(labeled_comments.shape)\n",
    "        if isinstance(test_size, int):\n",
    "            test_size = test_size / labeled_comments.shape[0]\n",
    "        sss = StratifiedShuffleSplit(n_splits=1, test_size=test_size, random_state = 0)\n",
    "        sss.get_n_splits(labeled_comments[\"message\"].values, labeled_comments[\"sentiment_label\"].values)\n",
    "        train_labeled_data = None\n",
    "        test_labeled_data = None\n",
    "        for train_index, test_index in sss.split(labeled_comments[\"message\"].values, labeled_comments[\"sentiment_label\"].values):\n",
    "            train_labeled_data = labeled_comments.iloc[train_index]\n",
    "            test_labeled_data = labeled_comments.iloc[test_index]\n",
    "        train_labeled_data.to_pickle(\"./train_labeled_data.pkl\")\n",
    "        test_labeled_data.to_pickle(\"./test_labeled_data.pkl\")\n",
    "        \n",
    "        return train_labeled_data, test_labeled_data\n",
    "        \n",
    "test_size = 280\n",
    "train_labeled_data, test_labeled_data = create_test_set(fb_comments_labeled_df, test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "56c46425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set.\n",
      "(280, 5)\n",
      "pos: 26%, neg: 74%\n"
     ]
    }
   ],
   "source": [
    "print(\"Test set.\")\n",
    "print(test_labeled_data.shape)\n",
    "print(\"pos: %d%%, neg: %d%%\" %(round(100*test_labeled_data[\"sentiment_label\"].value_counts()[1]/test_labeled_data.shape[0]), \n",
    "                               round(100*test_labeled_data[\"sentiment_label\"].value_counts()[0]/test_labeled_data.shape[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0d2e77dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set.\n",
      "(679, 5)\n",
      "pos: 26%, neg: 74%\n"
     ]
    }
   ],
   "source": [
    "print(\"Train set.\")\n",
    "print(train_labeled_data.shape)\n",
    "print(\"pos: %d%%, neg: %d%%\" %(round(100*train_labeled_data[\"sentiment_label\"].value_counts()[1]/train_labeled_data.shape[0]), \n",
    "                               round(100*train_labeled_data[\"sentiment_label\"].value_counts()[0]/train_labeled_data.shape[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0767baff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conserve this function just in case. Not being used at the moment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0fde72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(labeled_comments: pd.core.frame.DataFrame, unlabeled_comments: pd.core.frame.DataFrame,\n",
    "                     test_size: Union[int, float], class_percentages: dict, new_split: bool = False, \n",
    "                     display_class_percentages: bool = False, test_file: str = \"\") -> tuple:\n",
    "    df = labeled_comments\n",
    "    df2 = unlabeled_comments\n",
    "    \n",
    "    if new_split:\n",
    "        # Shuffle the data.\n",
    "        df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "        if class_percentages[\"same_as_train\"]:\n",
    "            # Create the train-test split ensuring the class percentages are maintained.\n",
    "            if isinstance(test_size, int):\n",
    "                # Convert the test size expressed as no. of comments to a percentage of labeled comments.\n",
    "                test_size = test_size / df.shape[0]        \n",
    "            sss = StratifiedShuffleSplit(n_splits=1, test_size=test_size, random_state=0)\n",
    "            sss.get_n_splits(df[\"message\"].values, df[\"sentiment_label\"].values)\n",
    "            train_data = None\n",
    "            test_data = None\n",
    "            for train_index, test_index in sss.split(df[\"message\"].values, df[\"sentiment_label\"].values):\n",
    "                train_data = df.iloc[train_index]\n",
    "                test_data = df.iloc[test_index]\n",
    "            test_neg = test_data[\"sentiment_label\"].value_counts()[0]/test_data.shape[0]\n",
    "            test_pos = test_data[\"sentiment_label\"].value_counts()[1]/test_data.shape[0]\n",
    "        else:\n",
    "            # Create the test set ensuring the requested class percentages.\n",
    "            test_neg = class_percentages[\"neg\"]\n",
    "            test_pos = class_percentages[\"pos\"]\n",
    "            if isinstance(test_size, float):\n",
    "                # Convert the test size expressed as a percentage of labeled comments to a no. of comments.\n",
    "                test_size = round(test_size * df.shape[0])\n",
    "            neg_comments = df.loc[df[\"sentiment_label\"] == \"neg\"].head(int(test_size * test_neg))\n",
    "            pos_comments = df.loc[df[\"sentiment_label\"] == \"pos\"].head(int(test_size * test_pos))\n",
    "            test_data = pd.concat([neg_comments, pos_comments])\n",
    "            # Create the train set with the remaining comments (class percentages are not controlled).\n",
    "            train_data = df[~df.comment_id.isin(test_data.comment_id)]\n",
    "        # Save the data.\n",
    "        train_data.to_pickle(\"./train_data.pkl\")\n",
    "        test_data.to_pickle(\"./test_data_%d-%d_neg-pos.pkl\" %(round(100*test_neg), round(100*test_neg)))\n",
    "    else:\n",
    "        test_file = \"./test_data.pkl\" if not test_file else \"./\" + test_file\n",
    "        train_data = pd.read_pickle(\"./train_data.pkl\")\n",
    "        test_data = pd.read_pickle(test_file)\n",
    "    \n",
    "    # Make tuples with labeled data: (feature, label). \n",
    "    unlabeled_arr = np.array([(message, \"UNK_UNK\") for message in df2[\"message\"].values])\n",
    "    train_arr = np.array([(row[\"message\"], row[\"sentiment_label\"]) for _, row in train_data.iterrows()])\n",
    "    test_arr = np.array([(row[\"message\"], row[\"sentiment_label\"]) for _, row in test_data.iterrows()])\n",
    "    \n",
    "    if display_class_percentages: \n",
    "        # Use code of previous versions (ugly).\n",
    "        train_labeled_data = train_arr\n",
    "        d_train = {\"pos\": 0, \"neg\": 0, \"UNK_UNK\": 0}\n",
    "        d_test = d_train.copy()\n",
    "        for _, label in train_labeled_data:\n",
    "            d_train[label] += 1\n",
    "        print(\"Percentages in train: \")\n",
    "        print(\"Negative: %d%% (%d)\" %(round(d_train[\"neg\"]*100/len(train_labeled_data)), d_train[\"neg\"]))\n",
    "        print(\"Positive:  %d%% (%d)\" %(round(d_train[\"pos\"]*100/len(train_labeled_data)), d_train[\"pos\"]))\n",
    "        print(\"\")\n",
    "\n",
    "        test_labeled_data = test_arr\n",
    "        for _, label in test_labeled_data:\n",
    "            d_test[label] += 1\n",
    "        print(\"Percentages in test: \")\n",
    "        print(\"Negative: %d%%\" %(round(d_test[\"neg\"]*100/len(test_labeled_data))))\n",
    "        print(\"Positive:  %d%%\" %(round(d_test[\"pos\"]*100/len(test_labeled_data))))\n",
    "        \n",
    "    # Create mask arrays.\n",
    "    unlabeled_masks = np.zeros(unlabeled_arr.shape[0], dtype=bool)\n",
    "    train_masks = np.ones(train_arr.shape[0], dtype=bool)\n",
    "    test_masks = np.ones(test_arr.shape[0], dtype=bool)\n",
    "    \n",
    "    # Extend the train data with the unlabeled data.\n",
    "    train_arr = np.append(train_arr, unlabeled_arr, axis=0)\n",
    "    train_masks = np.concatenate((train_masks, unlabeled_masks))\n",
    "\n",
    "    \n",
    "    return train_arr, train_masks, test_arr, test_masks\n",
    "\n",
    "new_split = True\n",
    "test_size =              # can be int (number of comments in test set) or float (percentage of train data to use as test)\n",
    "class_percentages = {\"pos\": .5, \"neg\": .5, \"same_as_train\": False}   # set to True if you want to maintain class percentages\n",
    "display = True\n",
    "test_file = \"test_data_50-50_neg-pos.pkl\"                           # set new_split to False first\n",
    "\n",
    "\n",
    "train_examples, train_label_masks, test_examples, test_label_masks = train_test_split(fb_comments_labeled_df, \n",
    "                                                                          fb_comments_unlabeled_df,\n",
    "                                                                          test_size,\n",
    "                                                                          class_percentages=class_percentages,\n",
    "                                                                          new_split=new_split,\n",
    "                                                                          display_class_percentages=display,\n",
    "                                                                          test_file = test_file)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-9.m79",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-9:m79"
  },
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
